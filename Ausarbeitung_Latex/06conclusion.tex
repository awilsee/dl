\mysection{Conclusion}
At the beginning, a lot of research was done to answer the general question of 'how can a network be integrated in a mobile application and run on a performance critical device'. During the research, Tensorflow Lite was chosen as an API which enables running a network on an Android mobile phone. Because Tensorflow supports the models MobileNet and Inception specifically for mobile application usage, both were chosen. Based on this decision, both models were investigated and a comparison of both of them was incorporated into this work. After determining which framework and models are suitable for mobile applicaton support, the installation began. Because of a good documentation the installation of Tensorflow and its necessary dependencies was done quickly. Following the tutorials the models were retrained on dog images. For a first, the optimization of the models to its full degree was omitted and the focus was to include the optimized models in the mobile application for running. Therefore, Tensorflow Lite was used to convert the .pb file to a .tflite file. The conversion was conducted successfully, but the produced .tflite file caused the app to terminate. After proving the versions of all used APIs and reconverting the models several times, the app still collapsed without throwing an error. Even after optimizing, rounding, quantizing the models with different commands, the app failed to run. In addition, the tutorials and documentation are kept short on this subject. Because of this behaviour, Tensorflow Mobile was used instead of Tensorflow Lite which is still in development mode. After integration of the .pb file and its corresponding label file, the Tensorflow version had to be adapted. If adding '+' in the dependency section for Tensorflow instead of the specified version, Android Studio installs the most recent one. Futhermore, after integrating an InceptionV3 model, no results were displayed while the app was running. Therefore, the threshold was adapted to a lower value in order to display low results from the network. Next, the models were optimized to their full degree based on varying the learning rate in relation to the training steps. Afterwards, the models were comprised and loaded into the mobile application. The result are two applications, one including MobileNet and another containing InceptionV3. In the last step, the models were compared based on performance, time expenditure for producing an optimized model and quality in accuracy. Especially for the time related evaluation, marker were placed in the scripts to measure the time needed for creating the bottlenecks, training on images and evaluating an image. The expectation was that the InceptionV3 was the most accurate model, but the one with the most required performance classifying an image in the mobile application. Futhermore, the MobileNet 1.0 was expected to be the most fastest and accurate model, whereas the MobileNet 0.50 might be accurate, but slower than its successor. It turned out contrary to expectations that the MobileNet 0.50 is the most accurate one with lowest performance required (refer to \secref{Evaluation}). As a last surprise, the app was running more smoothly on the Samsung S4 device than on the newer Motorola Moto X which contains a better processor.
